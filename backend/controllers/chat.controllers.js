import { Pinecone } from '@pinecone-database/pinecone';
import { HuggingFaceTransformersEmbeddings } from "@langchain/community/embeddings/huggingface_transformers";
import { PineconeStore } from "@langchain/community/vectorstores/pinecone";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { PromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables"; 
import { StringOutputParser } from "@langchain/core/output_parsers";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { Document } from "@langchain/core/documents";

let vectorStore; 


const cleanVietnameseText = (text) => {
    return text
      .replace(/Dƒ© nhi√™n r·∫±ng|H√¨nh dung r·∫±ng l√†|√†|·ª´m/g, '') 
      .replace(/\s+/g, ' ') 
      .trim();
  };
  
  // Chunking theo tokens (ph√π h·ª£p ti·∫øng Vi·ªát)
  const createTextSplitter = () => 
    new RecursiveCharacterTextSplitter({
      chunkSize: 500, 
      chunkOverlap: 50, 
      separators: ['\n\n', '\n', '. ', '! ', '? '], 
    });

export const initializeChatbotComponents = async () => {

    const pinecone = new Pinecone({
        apiKey: process.env.PINECONE_API_KEY,
    }, process.env.PINECONE_ENVIRONMENT);


    const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX_NAME);


    const embeddings = new HuggingFaceTransformersEmbeddings({
        modelName: "intfloat/multilingual-e5-small"
    });


    vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
        pineconeIndex,
    });


    const apiKeyGemini = process.env.GEMINI_API_KEY;
    const model = new ChatGoogleGenerativeAI({
        apiKey: apiKeyGemini,
        modelName: "gemini-1.5-pro",
    });

    return { vectorStore, embeddings, model, pineconeIndex };
};

export const indexLessonDataWithLangchain = async (lesson, embeddings, pineconeIndex) => {
    if (!lesson?._id || !lesson.summary || !lesson.transcript) return;
  

    const cleanedSummary = cleanVietnameseText(lesson.summary);
    const cleanedTranscript = cleanVietnameseText(lesson.transcript);
  

    const textSplitter = createTextSplitter();
    

    const transcriptChunks = await textSplitter.splitText(cleanedTranscript);
    

    const summaryChunks = await textSplitter.splitText(cleanedSummary);
  

    const allChunks = [...transcriptChunks, ...summaryChunks];
    const docs = allChunks.map((chunk, index) => 
      new Document({
        pageContent: chunk,
        metadata: { 
          lessonId: lesson._id,
          sourceType: index < transcriptChunks.length ? 'transcript' : 'summary', 
        },
      })
    );
  

    try {
      await PineconeStore.fromDocuments(docs, embeddings, { 
        pineconeIndex,
        namespace: 'lessons', 
      });
      console.log(`‚úÖ ƒê√£ index ${docs.length} chunks c·ªßa b√†i ${lesson._id} (Model: ${embeddings.modelName})`);
    } catch (error) {
      console.error("‚ùå L·ªói index:", error);
      throw new Error("Index failed: " + error.message);
    }
  };

  export const handleUserMessage = async (userQuestion, currentLessonData,currentLessonId, vectorStore, model) => {
    if (!userQuestion?.trim()) throw new Error("C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.");
  
    try {
  
      // B∆∞·ªõc 1: T√¨m ki·∫øm trong Pinecone (n·∫øu c·∫ßn)
      const pineconeResults = await vectorStore.similaritySearch(userQuestion, 3);
      const pineconeContext = pineconeResults.map(doc => doc.pageContent).join("\n");
  
      // B∆∞·ªõc 2: K·∫øt h·ª£p context t·ª´ b√†i h·ªçc + Pinecone
      const combinedContext = `
        TH√îNG TIN B√ÄI H·ªåC ${currentLessonId} HI·ªÜN T·∫†I:
        ${currentLessonData}
  
        TH√îNG TIN LI√äN QUAN T·ª™ H·ªÜ TH·ªêNG:
        ${pineconeContext}
      `;

  
      // B∆∞·ªõc 3: T·∫°o prompt v√† g·ªçi model
      const promptTemplate = PromptTemplate.fromTemplate(`
        B·∫°n ƒëang xem b√†i h·ªçc v·ªÅ **"React"**. H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau d·ª±a v√†o n·ªôi dung d∆∞·ªõi ƒë√¢y:
        ------
        {context}  // S·ª≠ d·ª•ng {context} - 'combinedContext' s·∫Ω ƒë∆∞·ª£c truy·ªÅn v√†o ƒë√¢y
        ------
        C√¢u h·ªèi: {question} // S·ª≠ d·ª•ng {question} - 'userQuestion' s·∫Ω ƒë∆∞·ª£c truy·ªÅn v√†o ƒë√¢y

        Y√™u c·∫ßu:
        - ∆Øu ti√™n th√¥ng tin t·ª´ "TH√îNG TIN B√ÄI H·ªåC HI·ªÜN T·∫†I".
        - N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, d√πng d·ªØ li·ªáu t·ª´ h·ªá th·ªëng.
        - Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, c√≥ icon c·∫£m x√∫c.
        - Kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn n·ªôi dung ngo√†i React hay li√™n quan t·ªõi l·∫≠p tr√¨nh n·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ m·ªôt n·ªôi dung n√†o ƒë√≥ g·∫ßn g·∫ßn li√™n quan t·ªõi react c·ª© vi·ªác tr·∫£ l·ªùi nh·∫±m cho ng∆∞·ªùi d√πng hi·ªÉu r√µ h∆°n , lu√¥n k√®m icon ph√π h·ª£p üöÄ.
        - N·∫øu ng∆∞·ªùi d·ªßng h·ªèi c√¢u h·ªèi li√™n quan t·ªõi vi·ªác t·∫°o c√¢u h·ªèi ho·∫∑c B√†i T·∫≠p √în T·∫≠p . Th√¨ b·∫°n s·∫Ω t·∫°o ra c√¢u h·ªèi v√† c√°c c√¢u tr·∫£ l·ªùi d·∫°ng tr·∫Øc nghi·ªám ABCD v√† m·ªói l·∫ßn ghi ra m·ªói c√¢u h·ªèi , m·ªói c√¢u tr·∫£ l·ªùi ABCD h√£y xu·ªëng d√≤ng m·ªói l·∫ßn  . Vui l√≤ng ch·ªâ t·∫°o ra c√¢u h·ªèi v√† kh√¥ng cho ƒë√°p √°n . Khi n√†o ng∆∞·ªùi d√πng c·∫ßn ƒë√°p √°n v√† h·ªèi m·ªõi c·∫ßn tr·∫£ l·ªùi ƒë√°p √°n c·ª• th·ªÉ . L∆∞u √Ω  t·ªëi ƒëa l√† 3 c√¢u h·ªèi m·ªói l·∫ßn v√† c√≥ ƒë√°nh s·ªë cho m·ªói c√¢u h·ªèi .
    `);
  
      const chain = RunnableSequence.from([
        { context: () => combinedContext, question: (input) => input.question },
        promptTemplate,
        model,
        new StringOutputParser(),
      ]);
  
      return await chain.invoke({ question: userQuestion });
    } catch (error) {
      console.error("[RAG Error]:", error);
      throw new Error(`X·ª≠ l√Ω th·∫•t b·∫°i: ${error.message}`);
    }
  };


  